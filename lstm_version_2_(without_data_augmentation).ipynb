{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d4061e",
      "metadata": {
        "id": "85d4061e"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import IPython.display as ipd\n",
        "import plotly.express as px\n",
        "import scipy.io.wavfile\n",
        "import sys\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41912f39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41912f39",
        "outputId": "738073d4-44cc-4286-dd47-2bce1f5c2062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#这个data只能在这个google folder里用\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "RAV = '/content/drive/MyDrive/Vision_Project/audio_speech_actors_01-24/'\n",
        "dir_list = os.listdir(RAV)\n",
        "\n",
        "emotion = []\n",
        "gender = []\n",
        "path = []\n",
        "feature = []\n",
        "for i in dir_list:\n",
        "    fname = os.listdir(RAV + i)\n",
        "    for f in fname:\n",
        "        part = f.split('.')[0].split('-')\n",
        "        emotion.append(int(part[2]))\n",
        "        temp = int(part[6])\n",
        "        if temp%2 == 0:\n",
        "            temp = \"female\"\n",
        "        else:\n",
        "            temp = \"male\"\n",
        "        gender.append(temp)\n",
        "        path.append(RAV + i + '/' + f)\n",
        "\n",
        "RAV_df = pd.DataFrame(emotion)\n",
        "RAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
        "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
        "RAV_df.columns = ['gender','emotion']\n",
        "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
        "RAV_df['source'] = 'RAVDESS'\n",
        "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
        "RAV_df = RAV_df.drop(['gender'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8336977d",
      "metadata": {
        "id": "8336977d"
      },
      "outputs": [],
      "source": [
        "def extract_features(data):\n",
        "    # ZCR\n",
        "    result = np.array([])\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result=np.hstack((result, zcr)) # stacking horizontally\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "    result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel)) # stacking horizontally\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_features(path):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "\n",
        "    # without augmentation\n",
        "    res1 = extract_features(data)\n",
        "    result = np.array(res1)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0092e172",
      "metadata": {
        "id": "0092e172"
      },
      "source": [
        "### 6. Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f3625636",
      "metadata": {
        "id": "f3625636"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "X, Y = [], []\n",
        "for path, emotion in zip(RAV_df.path, RAV_df.emotion):\n",
        "    feature = get_features(path)\n",
        "    X.append(feature)\n",
        "    Y.append(emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1b90371d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b90371d",
        "outputId": "a1c571c7-4a39-4f2e-8aaa-4b5717ba143e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1440, 1440, (1440,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(X), len(Y), RAV_df.path.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "378b54e0",
      "metadata": {
        "id": "378b54e0"
      },
      "outputs": [],
      "source": [
        "Features = pd.DataFrame(X)\n",
        "Features['labels'] = Y\n",
        "Features.to_csv('features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d5a6127c",
      "metadata": {
        "id": "d5a6127c"
      },
      "outputs": [],
      "source": [
        "X = Features.iloc[: ,:-1].values\n",
        "Y = Features['labels'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "94b721fc",
      "metadata": {
        "id": "94b721fc"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder()\n",
        "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
        "# Save the encoder\n",
        "with open('encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "196c70e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "196c70e5",
        "outputId": "e88a5f5c-0454-480e-e06e-279e207c0cd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1080, 162), (1080, 7), (360, 162), (360, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "aa86186f",
      "metadata": {
        "id": "aa86186f"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "# Save the scaler\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e3042aa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3042aa3",
        "outputId": "373f25f0-b757-4896-b6ce-54ab8c7c0c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1080, 162, 1), (1080, 7), (360, 162, 1), (360, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "x_train = np.expand_dims(x_train, axis=2)\n",
        "x_test = np.expand_dims(x_test, axis=2)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "FSXUvXBjcBkZ",
      "metadata": {
        "id": "FSXUvXBjcBkZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers, optimizers, callbacks\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04beb81a",
      "metadata": {
        "id": "04beb81a"
      },
      "source": [
        "### 7. Modelling :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1a8ba7e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a8ba7e2",
        "outputId": "9ee28975-a39a-44e6-fc1d-a53fbbd5f7c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 162, 64)           16896     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50375 (196.78 KB)\n",
            "Trainable params: 50375 (196.78 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "MODEL = Sequential()\n",
        "MODEL.add(layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "MODEL.add(layers.LSTM(64))\n",
        "MODEL.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "MODEL.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(MODEL.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=4, min_lr=0.000001)\n",
        "history=MODEL.fit(x_train, y_train, batch_size=50, epochs=200, validation_data=(x_test, y_test), callbacks=[rlrp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfmfoowJuDgg",
        "outputId": "6f12cf4c-7d98-48dd-a3fa-25ad4afe71ca"
      },
      "id": "rfmfoowJuDgg",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "22/22 [==============================] - 5s 57ms/step - loss: 1.8723 - accuracy: 0.2509 - val_loss: 1.8292 - val_accuracy: 0.2556 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7702 - accuracy: 0.2852 - val_loss: 1.8160 - val_accuracy: 0.2639 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7415 - accuracy: 0.3083 - val_loss: 1.7521 - val_accuracy: 0.2917 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.7149 - accuracy: 0.3222 - val_loss: 1.7658 - val_accuracy: 0.2944 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7306 - accuracy: 0.3148 - val_loss: 1.7777 - val_accuracy: 0.2889 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7057 - accuracy: 0.3315 - val_loss: 1.7249 - val_accuracy: 0.2972 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6979 - accuracy: 0.3250 - val_loss: 1.7115 - val_accuracy: 0.3139 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.7048 - accuracy: 0.3306 - val_loss: 1.7515 - val_accuracy: 0.2833 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6966 - accuracy: 0.3176 - val_loss: 1.7249 - val_accuracy: 0.3083 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6905 - accuracy: 0.3315 - val_loss: 1.7269 - val_accuracy: 0.3167 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.6755 - accuracy: 0.3324 - val_loss: 1.7184 - val_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.6604 - accuracy: 0.3417 - val_loss: 1.6796 - val_accuracy: 0.3528 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6415 - accuracy: 0.3620 - val_loss: 1.6584 - val_accuracy: 0.3556 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6342 - accuracy: 0.3574 - val_loss: 1.6760 - val_accuracy: 0.3639 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6481 - accuracy: 0.3454 - val_loss: 1.6707 - val_accuracy: 0.3278 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.6461 - accuracy: 0.3583 - val_loss: 1.6861 - val_accuracy: 0.3583 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6318 - accuracy: 0.3685 - val_loss: 1.6556 - val_accuracy: 0.3917 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6661 - accuracy: 0.3556 - val_loss: 1.6924 - val_accuracy: 0.3556 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.6279 - accuracy: 0.3796 - val_loss: 1.6747 - val_accuracy: 0.3444 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.6165 - accuracy: 0.3685 - val_loss: 1.6704 - val_accuracy: 0.3528 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.6171 - accuracy: 0.3731 - val_loss: 1.6613 - val_accuracy: 0.3444 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 1.6188 - accuracy: 0.3722 - val_loss: 1.6592 - val_accuracy: 0.3528 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.6199 - accuracy: 0.3611 - val_loss: 1.6441 - val_accuracy: 0.3556 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.6159 - accuracy: 0.3704 - val_loss: 1.6596 - val_accuracy: 0.3611 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 1.6067 - accuracy: 0.3704 - val_loss: 1.6517 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 1.5961 - accuracy: 0.3778 - val_loss: 1.6796 - val_accuracy: 0.3694 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.5916 - accuracy: 0.3778 - val_loss: 1.6576 - val_accuracy: 0.3583 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5813 - accuracy: 0.3889 - val_loss: 1.6213 - val_accuracy: 0.3694 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5784 - accuracy: 0.3769 - val_loss: 1.6572 - val_accuracy: 0.3556 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5939 - accuracy: 0.3907 - val_loss: 1.6342 - val_accuracy: 0.3861 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5772 - accuracy: 0.3926 - val_loss: 1.6846 - val_accuracy: 0.3611 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5952 - accuracy: 0.3833 - val_loss: 1.6589 - val_accuracy: 0.3694 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.5649 - accuracy: 0.3926 - val_loss: 1.6379 - val_accuracy: 0.3722 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6066 - accuracy: 0.3806 - val_loss: 1.6207 - val_accuracy: 0.3667 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5828 - accuracy: 0.4037 - val_loss: 1.6533 - val_accuracy: 0.3361 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5954 - accuracy: 0.3861 - val_loss: 1.6781 - val_accuracy: 0.3583 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5658 - accuracy: 0.4093 - val_loss: 1.6538 - val_accuracy: 0.3583 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5281 - accuracy: 0.4213 - val_loss: 1.6165 - val_accuracy: 0.3833 - lr: 4.0000e-04\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5307 - accuracy: 0.4148 - val_loss: 1.6080 - val_accuracy: 0.3722 - lr: 4.0000e-04\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.5152 - accuracy: 0.4250 - val_loss: 1.6309 - val_accuracy: 0.3806 - lr: 4.0000e-04\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5127 - accuracy: 0.4259 - val_loss: 1.6147 - val_accuracy: 0.3778 - lr: 4.0000e-04\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5322 - accuracy: 0.4194 - val_loss: 1.6572 - val_accuracy: 0.3722 - lr: 4.0000e-04\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5136 - accuracy: 0.4380 - val_loss: 1.6124 - val_accuracy: 0.3778 - lr: 4.0000e-04\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5204 - accuracy: 0.4250 - val_loss: 1.5856 - val_accuracy: 0.4028 - lr: 4.0000e-04\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5087 - accuracy: 0.4398 - val_loss: 1.6086 - val_accuracy: 0.3861 - lr: 4.0000e-04\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5080 - accuracy: 0.4278 - val_loss: 1.5784 - val_accuracy: 0.3944 - lr: 4.0000e-04\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4802 - accuracy: 0.4472 - val_loss: 1.5869 - val_accuracy: 0.3972 - lr: 4.0000e-04\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.5055 - accuracy: 0.4361 - val_loss: 1.5908 - val_accuracy: 0.4028 - lr: 4.0000e-04\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4764 - accuracy: 0.4472 - val_loss: 1.6201 - val_accuracy: 0.3833 - lr: 4.0000e-04\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4833 - accuracy: 0.4435 - val_loss: 1.5875 - val_accuracy: 0.4167 - lr: 4.0000e-04\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.4640 - accuracy: 0.4556 - val_loss: 1.5829 - val_accuracy: 0.4000 - lr: 4.0000e-04\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4929 - accuracy: 0.4380 - val_loss: 1.5777 - val_accuracy: 0.4194 - lr: 4.0000e-04\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.4846 - accuracy: 0.4435 - val_loss: 1.5989 - val_accuracy: 0.4278 - lr: 4.0000e-04\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 1.4846 - accuracy: 0.4306 - val_loss: 1.5922 - val_accuracy: 0.4111 - lr: 4.0000e-04\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 1.4608 - accuracy: 0.4343 - val_loss: 1.6316 - val_accuracy: 0.4028 - lr: 4.0000e-04\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4579 - accuracy: 0.4509 - val_loss: 1.5739 - val_accuracy: 0.4278 - lr: 4.0000e-04\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4449 - accuracy: 0.4676 - val_loss: 1.6126 - val_accuracy: 0.4139 - lr: 4.0000e-04\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4600 - accuracy: 0.4426 - val_loss: 1.5774 - val_accuracy: 0.4361 - lr: 4.0000e-04\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4434 - accuracy: 0.4565 - val_loss: 1.6044 - val_accuracy: 0.4056 - lr: 4.0000e-04\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4655 - accuracy: 0.4315 - val_loss: 1.5668 - val_accuracy: 0.4306 - lr: 4.0000e-04\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 1.4524 - accuracy: 0.4370 - val_loss: 1.5795 - val_accuracy: 0.4250 - lr: 4.0000e-04\n",
            "Epoch 62/200\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 1.4355 - accuracy: 0.4593 - val_loss: 1.5847 - val_accuracy: 0.4306 - lr: 4.0000e-04\n",
            "Epoch 63/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.4377 - accuracy: 0.4491 - val_loss: 1.5800 - val_accuracy: 0.4333 - lr: 4.0000e-04\n",
            "Epoch 64/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4522 - accuracy: 0.4463 - val_loss: 1.5722 - val_accuracy: 0.4333 - lr: 4.0000e-04\n",
            "Epoch 65/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4290 - accuracy: 0.4593 - val_loss: 1.5938 - val_accuracy: 0.4250 - lr: 4.0000e-04\n",
            "Epoch 66/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4174 - accuracy: 0.4685 - val_loss: 1.6162 - val_accuracy: 0.4056 - lr: 4.0000e-04\n",
            "Epoch 67/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4459 - accuracy: 0.4435 - val_loss: 1.5712 - val_accuracy: 0.4028 - lr: 4.0000e-04\n",
            "Epoch 68/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4364 - accuracy: 0.4500 - val_loss: 1.5752 - val_accuracy: 0.4222 - lr: 4.0000e-04\n",
            "Epoch 69/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4242 - accuracy: 0.4602 - val_loss: 1.5794 - val_accuracy: 0.4194 - lr: 4.0000e-04\n",
            "Epoch 70/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4127 - accuracy: 0.4667 - val_loss: 1.5929 - val_accuracy: 0.4194 - lr: 4.0000e-04\n",
            "Epoch 71/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4175 - accuracy: 0.4657 - val_loss: 1.5590 - val_accuracy: 0.4444 - lr: 4.0000e-04\n",
            "Epoch 72/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3891 - accuracy: 0.4750 - val_loss: 1.5675 - val_accuracy: 0.4417 - lr: 4.0000e-04\n",
            "Epoch 73/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3730 - accuracy: 0.4870 - val_loss: 1.5970 - val_accuracy: 0.4250 - lr: 4.0000e-04\n",
            "Epoch 74/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3901 - accuracy: 0.4741 - val_loss: 1.5729 - val_accuracy: 0.4333 - lr: 4.0000e-04\n",
            "Epoch 75/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3991 - accuracy: 0.4704 - val_loss: 1.5913 - val_accuracy: 0.4194 - lr: 4.0000e-04\n",
            "Epoch 76/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.3928 - accuracy: 0.4713 - val_loss: 1.6319 - val_accuracy: 0.4389 - lr: 4.0000e-04\n",
            "Epoch 77/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4199 - accuracy: 0.4685 - val_loss: 1.5679 - val_accuracy: 0.4444 - lr: 4.0000e-04\n",
            "Epoch 78/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3671 - accuracy: 0.4824 - val_loss: 1.5732 - val_accuracy: 0.4361 - lr: 1.6000e-04\n",
            "Epoch 79/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3513 - accuracy: 0.4972 - val_loss: 1.5617 - val_accuracy: 0.4333 - lr: 1.6000e-04\n",
            "Epoch 80/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3474 - accuracy: 0.4907 - val_loss: 1.5753 - val_accuracy: 0.4389 - lr: 1.6000e-04\n",
            "Epoch 81/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3564 - accuracy: 0.4935 - val_loss: 1.5738 - val_accuracy: 0.4306 - lr: 1.6000e-04\n",
            "Epoch 82/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3530 - accuracy: 0.4880 - val_loss: 1.5761 - val_accuracy: 0.4472 - lr: 1.6000e-04\n",
            "Epoch 83/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3311 - accuracy: 0.5009 - val_loss: 1.5764 - val_accuracy: 0.4472 - lr: 1.6000e-04\n",
            "Epoch 84/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3304 - accuracy: 0.5000 - val_loss: 1.5608 - val_accuracy: 0.4500 - lr: 1.6000e-04\n",
            "Epoch 85/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3303 - accuracy: 0.5000 - val_loss: 1.5705 - val_accuracy: 0.4417 - lr: 1.6000e-04\n",
            "Epoch 86/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3315 - accuracy: 0.4944 - val_loss: 1.5784 - val_accuracy: 0.4444 - lr: 1.6000e-04\n",
            "Epoch 87/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3286 - accuracy: 0.4917 - val_loss: 1.5758 - val_accuracy: 0.4389 - lr: 1.6000e-04\n",
            "Epoch 88/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3337 - accuracy: 0.4963 - val_loss: 1.6022 - val_accuracy: 0.4250 - lr: 1.6000e-04\n",
            "Epoch 89/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3303 - accuracy: 0.5009 - val_loss: 1.5977 - val_accuracy: 0.4333 - lr: 1.6000e-04\n",
            "Epoch 90/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3198 - accuracy: 0.5000 - val_loss: 1.6023 - val_accuracy: 0.4250 - lr: 1.6000e-04\n",
            "Epoch 91/200\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.3266 - accuracy: 0.5028 - val_loss: 1.5787 - val_accuracy: 0.4472 - lr: 1.6000e-04\n",
            "Epoch 92/200\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 1.3234 - accuracy: 0.5093 - val_loss: 1.5870 - val_accuracy: 0.4389 - lr: 1.6000e-04\n",
            "Epoch 93/200\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.3050 - accuracy: 0.5056 - val_loss: 1.5787 - val_accuracy: 0.4500 - lr: 1.6000e-04\n",
            "Epoch 94/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.3077 - accuracy: 0.5074 - val_loss: 1.5806 - val_accuracy: 0.4444 - lr: 1.6000e-04\n",
            "Epoch 95/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.3041 - accuracy: 0.5083 - val_loss: 1.6205 - val_accuracy: 0.4222 - lr: 1.6000e-04\n",
            "Epoch 96/200\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 1.3142 - accuracy: 0.5037 - val_loss: 1.6066 - val_accuracy: 0.4333 - lr: 1.6000e-04\n",
            "Epoch 97/200\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 1.3280 - accuracy: 0.5046 - val_loss: 1.5808 - val_accuracy: 0.4306 - lr: 1.6000e-04\n",
            "Epoch 98/200\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.3126 - accuracy: 0.5000 - val_loss: 1.5779 - val_accuracy: 0.4306 - lr: 1.6000e-04\n",
            "Epoch 99/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.3168 - accuracy: 0.5000 - val_loss: 1.5900 - val_accuracy: 0.4361 - lr: 1.6000e-04\n",
            "Epoch 100/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2956 - accuracy: 0.5111 - val_loss: 1.5810 - val_accuracy: 0.4444 - lr: 6.4000e-05\n",
            "Epoch 101/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2829 - accuracy: 0.5130 - val_loss: 1.5959 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 102/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2837 - accuracy: 0.5185 - val_loss: 1.5918 - val_accuracy: 0.4444 - lr: 6.4000e-05\n",
            "Epoch 103/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2768 - accuracy: 0.5139 - val_loss: 1.6067 - val_accuracy: 0.4444 - lr: 6.4000e-05\n",
            "Epoch 104/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2840 - accuracy: 0.5204 - val_loss: 1.5906 - val_accuracy: 0.4472 - lr: 6.4000e-05\n",
            "Epoch 105/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2862 - accuracy: 0.5167 - val_loss: 1.5881 - val_accuracy: 0.4472 - lr: 6.4000e-05\n",
            "Epoch 106/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2767 - accuracy: 0.5102 - val_loss: 1.5926 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 107/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2760 - accuracy: 0.5176 - val_loss: 1.5954 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 108/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2750 - accuracy: 0.5148 - val_loss: 1.5945 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 109/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2715 - accuracy: 0.5167 - val_loss: 1.5967 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 110/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2705 - accuracy: 0.5185 - val_loss: 1.5928 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 111/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2698 - accuracy: 0.5111 - val_loss: 1.6023 - val_accuracy: 0.4444 - lr: 6.4000e-05\n",
            "Epoch 112/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2668 - accuracy: 0.5194 - val_loss: 1.6017 - val_accuracy: 0.4472 - lr: 6.4000e-05\n",
            "Epoch 113/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2680 - accuracy: 0.5167 - val_loss: 1.5984 - val_accuracy: 0.4472 - lr: 6.4000e-05\n",
            "Epoch 114/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2675 - accuracy: 0.5157 - val_loss: 1.6122 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 115/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2647 - accuracy: 0.5213 - val_loss: 1.5897 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 116/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2693 - accuracy: 0.5111 - val_loss: 1.6073 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 117/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2658 - accuracy: 0.5148 - val_loss: 1.6140 - val_accuracy: 0.4306 - lr: 6.4000e-05\n",
            "Epoch 118/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2647 - accuracy: 0.5148 - val_loss: 1.6194 - val_accuracy: 0.4417 - lr: 6.4000e-05\n",
            "Epoch 119/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2602 - accuracy: 0.5185 - val_loss: 1.6148 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 120/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2617 - accuracy: 0.5213 - val_loss: 1.6056 - val_accuracy: 0.4333 - lr: 6.4000e-05\n",
            "Epoch 121/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2620 - accuracy: 0.5204 - val_loss: 1.6208 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 122/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2588 - accuracy: 0.5259 - val_loss: 1.6128 - val_accuracy: 0.4306 - lr: 6.4000e-05\n",
            "Epoch 123/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2566 - accuracy: 0.5194 - val_loss: 1.6151 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 124/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2566 - accuracy: 0.5278 - val_loss: 1.6151 - val_accuracy: 0.4222 - lr: 6.4000e-05\n",
            "Epoch 125/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.2584 - accuracy: 0.5231 - val_loss: 1.6194 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 126/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2527 - accuracy: 0.5204 - val_loss: 1.6152 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 127/200\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 1.2497 - accuracy: 0.5204 - val_loss: 1.6235 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 128/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.2502 - accuracy: 0.5167 - val_loss: 1.6162 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 129/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2559 - accuracy: 0.5148 - val_loss: 1.6255 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 130/200\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.2573 - accuracy: 0.5213 - val_loss: 1.6397 - val_accuracy: 0.4361 - lr: 6.4000e-05\n",
            "Epoch 131/200\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.2535 - accuracy: 0.5269 - val_loss: 1.6226 - val_accuracy: 0.4389 - lr: 6.4000e-05\n",
            "Epoch 132/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2490 - accuracy: 0.5269 - val_loss: 1.6240 - val_accuracy: 0.4278 - lr: 2.5600e-05\n",
            "Epoch 133/200\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2414 - accuracy: 0.5250 - val_loss: 1.6224 - val_accuracy: 0.4389 - lr: 2.5600e-05\n",
            "Epoch 134/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2382 - accuracy: 0.5241 - val_loss: 1.6229 - val_accuracy: 0.4361 - lr: 2.5600e-05\n",
            "Epoch 135/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2422 - accuracy: 0.5287 - val_loss: 1.6427 - val_accuracy: 0.4250 - lr: 2.5600e-05\n",
            "Epoch 136/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2402 - accuracy: 0.5269 - val_loss: 1.6203 - val_accuracy: 0.4361 - lr: 2.5600e-05\n",
            "Epoch 137/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2377 - accuracy: 0.5259 - val_loss: 1.6225 - val_accuracy: 0.4361 - lr: 2.5600e-05\n",
            "Epoch 138/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2379 - accuracy: 0.5259 - val_loss: 1.6334 - val_accuracy: 0.4417 - lr: 2.5600e-05\n",
            "Epoch 139/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2388 - accuracy: 0.5269 - val_loss: 1.6277 - val_accuracy: 0.4389 - lr: 2.5600e-05\n",
            "Epoch 140/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2350 - accuracy: 0.5278 - val_loss: 1.6281 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 141/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2348 - accuracy: 0.5259 - val_loss: 1.6315 - val_accuracy: 0.4389 - lr: 2.5600e-05\n",
            "Epoch 142/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2343 - accuracy: 0.5250 - val_loss: 1.6288 - val_accuracy: 0.4306 - lr: 2.5600e-05\n",
            "Epoch 143/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2337 - accuracy: 0.5241 - val_loss: 1.6283 - val_accuracy: 0.4278 - lr: 2.5600e-05\n",
            "Epoch 144/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2342 - accuracy: 0.5278 - val_loss: 1.6266 - val_accuracy: 0.4306 - lr: 2.5600e-05\n",
            "Epoch 145/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2340 - accuracy: 0.5269 - val_loss: 1.6355 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 146/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2343 - accuracy: 0.5269 - val_loss: 1.6331 - val_accuracy: 0.4306 - lr: 2.5600e-05\n",
            "Epoch 147/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2334 - accuracy: 0.5259 - val_loss: 1.6371 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 148/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2328 - accuracy: 0.5269 - val_loss: 1.6345 - val_accuracy: 0.4306 - lr: 2.5600e-05\n",
            "Epoch 149/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2304 - accuracy: 0.5250 - val_loss: 1.6354 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 150/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2318 - accuracy: 0.5231 - val_loss: 1.6381 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 151/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2301 - accuracy: 0.5278 - val_loss: 1.6361 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 152/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2297 - accuracy: 0.5269 - val_loss: 1.6386 - val_accuracy: 0.4278 - lr: 2.5600e-05\n",
            "Epoch 153/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2309 - accuracy: 0.5278 - val_loss: 1.6430 - val_accuracy: 0.4361 - lr: 2.5600e-05\n",
            "Epoch 154/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2295 - accuracy: 0.5278 - val_loss: 1.6362 - val_accuracy: 0.4278 - lr: 2.5600e-05\n",
            "Epoch 155/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2283 - accuracy: 0.5296 - val_loss: 1.6405 - val_accuracy: 0.4306 - lr: 2.5600e-05\n",
            "Epoch 156/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2301 - accuracy: 0.5259 - val_loss: 1.6395 - val_accuracy: 0.4361 - lr: 2.5600e-05\n",
            "Epoch 157/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2299 - accuracy: 0.5306 - val_loss: 1.6414 - val_accuracy: 0.4333 - lr: 2.5600e-05\n",
            "Epoch 158/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2294 - accuracy: 0.5269 - val_loss: 1.6519 - val_accuracy: 0.4389 - lr: 2.5600e-05\n",
            "Epoch 159/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2296 - accuracy: 0.5269 - val_loss: 1.6453 - val_accuracy: 0.4444 - lr: 2.5600e-05\n",
            "Epoch 160/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2234 - accuracy: 0.5278 - val_loss: 1.6402 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 161/200\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.2228 - accuracy: 0.5296 - val_loss: 1.6410 - val_accuracy: 0.4361 - lr: 1.0240e-05\n",
            "Epoch 162/200\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 1.2234 - accuracy: 0.5259 - val_loss: 1.6422 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 163/200\n",
            "22/22 [==============================] - 1s 43ms/step - loss: 1.2226 - accuracy: 0.5287 - val_loss: 1.6423 - val_accuracy: 0.4389 - lr: 1.0240e-05\n",
            "Epoch 164/200\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 1.2223 - accuracy: 0.5269 - val_loss: 1.6412 - val_accuracy: 0.4361 - lr: 1.0240e-05\n",
            "Epoch 165/200\n",
            "22/22 [==============================] - 1s 46ms/step - loss: 1.2221 - accuracy: 0.5287 - val_loss: 1.6410 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 166/200\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.2215 - accuracy: 0.5259 - val_loss: 1.6432 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 167/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2214 - accuracy: 0.5269 - val_loss: 1.6431 - val_accuracy: 0.4389 - lr: 1.0240e-05\n",
            "Epoch 168/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2213 - accuracy: 0.5278 - val_loss: 1.6429 - val_accuracy: 0.4361 - lr: 1.0240e-05\n",
            "Epoch 169/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2207 - accuracy: 0.5296 - val_loss: 1.6423 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 170/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2206 - accuracy: 0.5259 - val_loss: 1.6422 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 171/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2215 - accuracy: 0.5324 - val_loss: 1.6435 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 172/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2203 - accuracy: 0.5278 - val_loss: 1.6431 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 173/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2201 - accuracy: 0.5278 - val_loss: 1.6436 - val_accuracy: 0.4361 - lr: 1.0240e-05\n",
            "Epoch 174/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2203 - accuracy: 0.5287 - val_loss: 1.6443 - val_accuracy: 0.4361 - lr: 1.0240e-05\n",
            "Epoch 175/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2196 - accuracy: 0.5306 - val_loss: 1.6443 - val_accuracy: 0.4278 - lr: 1.0240e-05\n",
            "Epoch 176/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2201 - accuracy: 0.5315 - val_loss: 1.6421 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 177/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2194 - accuracy: 0.5287 - val_loss: 1.6441 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 178/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2189 - accuracy: 0.5315 - val_loss: 1.6446 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 179/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2190 - accuracy: 0.5296 - val_loss: 1.6431 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 180/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2184 - accuracy: 0.5306 - val_loss: 1.6448 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 181/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2186 - accuracy: 0.5287 - val_loss: 1.6438 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 182/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2185 - accuracy: 0.5324 - val_loss: 1.6442 - val_accuracy: 0.4278 - lr: 1.0240e-05\n",
            "Epoch 183/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2181 - accuracy: 0.5324 - val_loss: 1.6447 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 184/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2194 - accuracy: 0.5306 - val_loss: 1.6445 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 185/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2175 - accuracy: 0.5324 - val_loss: 1.6456 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 186/200\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2181 - accuracy: 0.5296 - val_loss: 1.6448 - val_accuracy: 0.4278 - lr: 1.0240e-05\n",
            "Epoch 187/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2167 - accuracy: 0.5306 - val_loss: 1.6450 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 188/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2175 - accuracy: 0.5315 - val_loss: 1.6450 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 189/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2169 - accuracy: 0.5324 - val_loss: 1.6488 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 190/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2168 - accuracy: 0.5296 - val_loss: 1.6443 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 191/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2165 - accuracy: 0.5306 - val_loss: 1.6459 - val_accuracy: 0.4333 - lr: 1.0240e-05\n",
            "Epoch 192/200\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2164 - accuracy: 0.5315 - val_loss: 1.6459 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 193/200\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.2168 - accuracy: 0.5315 - val_loss: 1.6472 - val_accuracy: 0.4250 - lr: 1.0240e-05\n",
            "Epoch 194/200\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.2154 - accuracy: 0.5343 - val_loss: 1.6461 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 195/200\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 1.2173 - accuracy: 0.5343 - val_loss: 1.6468 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 196/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2163 - accuracy: 0.5333 - val_loss: 1.6465 - val_accuracy: 0.4278 - lr: 1.0240e-05\n",
            "Epoch 197/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2144 - accuracy: 0.5343 - val_loss: 1.6473 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 198/200\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 1.2145 - accuracy: 0.5306 - val_loss: 1.6479 - val_accuracy: 0.4306 - lr: 1.0240e-05\n",
            "Epoch 199/200\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 1.2153 - accuracy: 0.5306 - val_loss: 1.6474 - val_accuracy: 0.4250 - lr: 1.0240e-05\n",
            "Epoch 200/200\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2144 - accuracy: 0.5343 - val_loss: 1.6474 - val_accuracy: 0.4306 - lr: 1.0240e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.evaluate(x_test,y_test)[1]*100"
      ],
      "metadata": {
        "id": "NHy_gCZP6oxY",
        "outputId": "d69f6fdc-b79f-4c4a-a1bb-dae2940239bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NHy_gCZP6oxY",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 17ms/step - loss: 1.6474 - accuracy: 0.4306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.05555522441864"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CR3-rE6H6pEN"
      },
      "id": "CR3-rE6H6pEN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 107620,
          "sourceId": 256618,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1052.963631,
      "end_time": "2024-03-29T03:32:04.047193",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-29T03:14:31.083562",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}